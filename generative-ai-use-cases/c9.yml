AWSTemplateFormatVersion: '2010-09-09'
Description: 'Cloud9 environment for generative-ai-use-cases'

Resources:
 DeployBucket:
   Type: AWS::S3::Bucket
   Properties:
     BucketName: !Sub 'genu-deploy-${AWS::AccountId}-${AWS::Region}'

 DeployBucketCustomResource:
   Type: Custom::DeployResource
   Properties:
     ServiceToken: !GetAtt 'DeployBucketCustomResourceFunction.Arn'
     BucketName: !Ref 'DeployBucket'

 DeployBucketCustomResourceFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Runtime: python3.12
      Timeout: 120
      Code:
        ZipFile: |
          import os
          import zipfile
          import boto3
          import cfnresponse

          def handler(event, context):
            s3 = boto3.client('s3')
            bucket_name = event['ResourceProperties']['BucketName']

            if event['RequestType'] == 'Create' or event['RequestType'] == 'Update':
              # Create create.sh file locally
              with open('/tmp/create.sh', 'w') as file:
                file.write('''#!/bin/bash
          cd /home/ec2-user/environment

          RAG_ENABLED=true
          MODEL_REGION="us-west-2"
          MODEL_IDS='["anthropic.claude-3-sonnet-20240229-v1:0", "anthropic.claude-3-haiku-20240307-v1:0", "anthropic.claude-3-opus-20240229-v1:0"]'

          git clone https://github.com/aws-samples/generative-ai-use-cases-jp.git

          if [ $? -eq 0 ]; then
            cd /home/ec2-user/environment/generative-ai-use-cases-jp
            jq --arg rag "$RAG_ENABLED" '.context.ragEnabled = ($rag == "true")' packages/cdk/cdk.json > tmp.json && mv tmp.json packages/cdk/cdk.json
            jq --arg region "$MODEL_REGION" '.context.modelRegion = $region' packages/cdk/cdk.json > tmp.json && mv tmp.json packages/cdk/cdk.json
            jq --argjson ids "$MODEL_IDS" '.context.modelIds = $ids' packages/cdk/cdk.json > tmp.json && mv tmp.json packages/cdk/cdk.json
          fi

          cd /home/ec2-user/environment/generative-ai-use-cases-jp
          npm ci
          npx -w packages/cdk cdk bootstrap
          npm -w packages/cdk run cdk deploy -- --all --require-approval never
          ''')

              # Create delete.sh file locally
              with open('/tmp/delete.sh', 'w') as file:
                file.write('''#!/bin/bash
          cd /home/ec2-user/environment/generative-ai-use-cases-jp
          npm -w packages/cdk run cdk destroy -- --all
          ''')

              # Create deploy.zip locally
              with zipfile.ZipFile('/tmp/deploy.zip', 'w') as zip_file:
                zip_file.write('/tmp/create.sh', 'create.sh')
                zip_file.write('/tmp/delete.sh', 'delete.sh')

              # Upload deploy.zip to S3
              s3.upload_file('/tmp/deploy.zip', bucket_name, 'deploy.zip')

            elif event['RequestType'] == 'Delete':
              bucket = boto3.resource('s3').Bucket(bucket_name)
              bucket.objects.all().delete()

            cfnresponse.send(event, context, cfnresponse.SUCCESS, {})

      Role: !GetAtt 'DeployBucketLambdaExecutionRole.Arn'

 DeployBucketLambdaExecutionRole:
   Type: AWS::IAM::Role
   Properties:
     AssumeRolePolicyDocument:
       Version: '2012-10-17'
       Statement:
         - Effect: Allow
           Principal:
             Service:
               - lambda.amazonaws.com
           Action:
             - sts:AssumeRole
     Policies:
       - PolicyName: s3-access
         PolicyDocument:
           Version: '2012-10-17'
           Statement:
             - Effect: Allow
               Action:
                 - s3:PutObject
                 - s3:DeleteObject
                 - s3:ListBucket
                 - s3:DeleteObjectVersion
               Resource:
                 - !Sub 'arn:aws:s3:::${DeployBucket}'
                 - !Sub 'arn:aws:s3:::${DeployBucket}/*'
       - PolicyName: ec2-access
         PolicyDocument:
           Version: '2012-10-17'
           Statement:
             - Effect: Allow
               Action:
                 - ec2:DescribeInstances
                 - ec2:ModifyVolume
                 - ec2:RebootInstances
               Resource: '*'
       - PolicyName: cloudwatch-logs
         PolicyDocument:
           Version: '2012-10-17'
           Statement:
             - Effect: Allow
               Action:
                 - logs:CreateLogGroup
                 - logs:CreateLogStream
                 - logs:PutLogEvents
               Resource: !Sub 'arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*'

 CodeCommitRepo:
   Type: AWS::CodeCommit::Repository
   DependsOn: DeployBucketCustomResource
   Properties:
     RepositoryName: genu-deploy
     RepositoryDescription: 'Repository for deploying resources'
     Code:
       S3:
         Bucket: !Ref 'DeployBucket'
         Key: deploy.zip

 Cloud9Environment:
   Type: AWS::Cloud9::EnvironmentEC2
   Properties:
     Name: cloud9-for-prototyping
     Description: Created by cloud9-setup-for-prototyping
     InstanceType: t2.medium
     ImageId: amazonlinux-2023-x86_64
     AutomaticStopTimeMinutes: 30
     Repositories:
       - PathComponent: /genu-deploy
         RepositoryUrl: !GetAtt 'CodeCommitRepo.CloneUrlHttp'

 ResizeEBSVolumeFunction:
   Type: AWS::Lambda::Function
   Properties:
     Handler: index.handler
     Runtime: python3.12
     Timeout: 120
     Code:
       ZipFile: |
         import boto3
         import cfnresponse
         import time

         def handler(event, context):
             if event['RequestType'] == 'Create':
                 environment_id = event['ResourceProperties']['EnvironmentId']
                 volume_size = int(event['ResourceProperties']['VolumeSize'])

                 ec2 = boto3.client('ec2')
                 response = ec2.describe_instances(Filters=[{'Name': 'tag:aws:cloud9:environment', 'Values': [environment_id]}])

                 instance_id = response['Reservations'][0]['Instances'][0]['InstanceId']
                 volume_id = response['Reservations'][0]['Instances'][0]['BlockDeviceMappings'][0]['Ebs']['VolumeId']

                 ec2.modify_volume(VolumeId=volume_id, Size=volume_size)

                 time.sleep(30)
                 ec2.reboot_instances(InstanceIds=[instance_id])

             cfnresponse.send(event, context, cfnresponse.SUCCESS, {})

     Role: !GetAtt 'DeployBucketLambdaExecutionRole.Arn'

 ResizeEBSVolumeCustomResource:
   Type: Custom::ResizeEBSVolume
   Properties:
     ServiceToken: !GetAtt 'ResizeEBSVolumeFunction.Arn'
     EnvironmentId: !Ref 'Cloud9Environment'
     VolumeSize: 25
   DependsOn: Cloud9Environment